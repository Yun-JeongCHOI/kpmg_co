{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\82105\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\82105\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 782/782 [00:00<00:00, 41.4kB/s]\n",
      "c:\\Users\\82105\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\82105\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 1.10G/1.10G [06:53<00:00, 2.67MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 2.41k/2.41k [00:00<00:00, 172kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.92M/2.92M [00:01<00:00, 1.52MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 2.20k/2.20k [00:00<00:00, 201kB/s]\n"
     ]
    }
   ],
   "source": [
    "# hugging-face model 불러오기\n",
    "# pip install transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('eenzeenee/t5-base-korean-summarization')\n",
    "tokenizer = AutoTokenizer.from_pretrained('eenzeenee/t5-base-korean-summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코퍼스 키워드로 추출된 공시 데이터 불러오기\n",
    "path = './1-2. ESG report/'\n",
    "dir = 'output/'\n",
    "file_list = os.listdir(path+dir)\n",
    "# 이중 공시 데이터만 가져옴\n",
    "file_list = [file for file in file_list if file.startswith(\"extracted\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    df = pd.read_csv(file)\n",
    "    acc = df.drop_duplicates(subset = 'keyword')\n",
    "    acc['text'] = ''\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        s = ''\n",
    "        sub = df[df['keyword']==row['keyword']]\n",
    "        for _, i in sub.iterrows():\n",
    "            s += i['text']\n",
    "        acc.loc[acc['keyword']==row['keyword'],'text'] = s\n",
    "    \n",
    "\n",
    "    out = acc.copy()\n",
    "    out['text'] = ''\n",
    "\n",
    "    for _, item in acc.iterrows():\n",
    "        inputs = item['text']\n",
    "        inputs = tokenizer(inputs, max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "        output = model.generate(**inputs, num_beams=3, do_sample=True, min_length=10, max_length=128)\n",
    "        decoded_output = tokenizer.batch_decode(output, skip_special_tokens=False)[0]\n",
    "        result = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "        out.loc[out['keyword']==item['keyword'], 'text'] = result\n",
    "\n",
    "    # output 폴더 없으면 만들기 \n",
    "    if not os.path.isdir(path + 'output/'):\n",
    "        os.mkdir(path + 'output/')\n",
    "    out.to_csv(path+dir+'summarized_'+file.replace(\"extracted_\", \"\").replace('.csv',''), index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82105\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "c:\\Users\\82105\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "c:\\Users\\82105\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    }
   ],
   "source": [
    "# file = './1-2. ESG report/output/hyundaehomeshopping_2023.csv'\n",
    "\n",
    "# df = pd.read_csv(file)\n",
    "# acc = df.drop_duplicates(subset = 'keyword')\n",
    "# acc['text'] = ''\n",
    "\n",
    "# for _, row in acc.iterrows():\n",
    "#     s = ''\n",
    "#     sub = df[df['keyword']==row['keyword']]\n",
    "#     for _, i in sub.iterrows():\n",
    "#         s += i['text']\n",
    "#     acc.loc[out['keyword']==row['keyword'],'text'] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = acc.copy()\n",
    "# out['text'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  1369,  4186,   262,   222,  4415,   429,   222,  5374, 30402,\n",
      "           222,  1588,  5374,   464,   381,   222,  4192,  5374,   464,   222,\n",
      "           783,   222,  1349,  5374,   464,   293,   222, 10868,   222,   334,\n",
      "           222,  1813,   222,   480,  2304,   222,  1349,  5374,   464,   222,\n",
      "         11587,   291,   222,   863,   222,  4128,   515,   222,  3092,   222,\n",
      "           450,   222,  1349,   222,  1409,   222,  2001,   279,   222,  2430,\n",
      "         34939,   222,  1177,   333]])\n",
      "현대홈쇼핑이 배출하는 폐기물은 사무폐기물과 물류폐기물 그리고 방송폐기물로 나눌 수 있으며 당사는 방송폐기물 감축을 위해 미디어월 구축 등 방송 환경 변화에 적극적인 투자를\n",
      "현대홈쇼핑이 배출하는 폐기물은 사무폐기물과 물류폐기물 그리고 방송폐기물로 나눌 수 있으며 당사는 방송폐기물 감축을 위해 미디어월 구축 등 방송 환경 변화에 적극적인 투자를\n",
      "tensor([[    0,  1369,  4186,   311,   222,   464,   222, 15585,   222,  2749,\n",
      "           333,   222,   863,   222,  8095,   222,   417,  2647,   222,  1653,\n",
      "         35655,   222,  3092,   443,   222,  4328,   222,  5562,   222,  4599,\n",
      "           333,   222,  2293,   222,  1653,   279,   222,  5782,   766,   222,\n",
      "          3018,   222,  1250,   222,   578,   389,   222, 16125,   222,  8069,\n",
      "           291,   222,  4316,   443,   222,   738,    15,     1]])\n",
      "현대홈쇼핑은 물 사용량 감소를 위해 사내 중수도 시설물을 구축하고 친환경 캠페인 스티커를 주요 시설에 부착하여 일상 생활 속에서 용수 절약을 실천하고 있습니다.\n",
      "현대홈쇼핑은 물 사용량 감소를 위해 사내 중수도 시설물을 구축하고 친환경 캠페인 스티커를 주요 시설에 부착하여 일상 생활 속에서 용수 절약을 실천하고 있습니다.\n",
      "tensor([[    0,  1369,  4186,   311,   222,  2542,   222,  1409,  2255,  3210,\n",
      "           333,   222,  3092,   443,   222,  1409,  2255,   222,  2078,   333,\n",
      "           222,  6091,  7620,   222, 13400,  2698,   222, 24146,   381,   222,\n",
      "          2664,  1909,   222,   450,   279,   222,   745,   222,  1001,   333,\n",
      "           222,  1856,   443,   222, 13784,   222,  2459,   291,   222,  6091,\n",
      "           766,   222,  2119,   403,   373,   222,  2291,  6787,   222,  1037,\n",
      "          3454,   685,   291,   222]])\n",
      "현대홈쇼핑은 내부 환경경영체계를 구축하고 환경경영 목표를 수립하였으며 온실가스 배출량과 에너지소비 등에 대한 관리를 강화하고 중장기 전략을 수립하여 단계적으로 2050 탄소중립을 \n",
      "현대홈쇼핑은 내부 환경경영체계를 구축하고 환경경영 목표를 수립하였으며 온실가스 배출량과 에너지소비 등에 대한 관리를 강화하고 중장기 전략을 수립하여 단계적으로 2050 탄소중립을\n",
      "tensor([[    0,  1369,  4186,   311,   222,   464,   222, 15585,   222,  2749,\n",
      "           333,   222,   863,   222,  8095,   222,   417,  2647,   222,  1653,\n",
      "         35655,   222,  3092,  1716,   222, 16469,   222,   948,   222,  5393,\n",
      "           222, 16125,   222,   857,   222, 15585,   302,   222,  2291,   222,\n",
      "           333,   222,  9288,   443,   222,   530,    15,   222,   480,  2304,\n",
      "           222,   511,   222,   509,  3652,   681,   222,  1102,   305,   222,\n",
      "          6159,   222,  1049,   291]])\n",
      "현대홈쇼핑은 물 사용량 감소를 위해 사내 중수도 시설물을 구축했고 이를 통해 연간 용수 총 사용량의 20 를 재활용하고 있다. 당사는 각 배출처별 다양한 절감 활동을\n",
      "현대홈쇼핑은 물 사용량 감소를 위해 사내 중수도 시설물을 구축했고 이를 통해 연간 용수 총 사용량의 20 를 재활용하고 있다.\n",
      "tensor([[    0,  1369,  4186,   311,   222,  2542,   222,  1409,  2255,  3210,\n",
      "           333,   222,  3092,   443,   222,  1409,  2255,   222,  2078,   333,\n",
      "           222,  6091,   766,   222, 13400,  2698,   222, 24146,   381,   222,\n",
      "          2664,  1909,   222,   450,   279,   222,   745,   222,  1001,   333,\n",
      "           222,  1856,   443,   222, 13784,   222,  2459,   291,   222,  6091,\n",
      "           766,   222,  2119,   403,   373,   222,  2291,  6787,   222,  1037,\n",
      "          3454,   685,   291,   222]])\n",
      "현대홈쇼핑은 내부 환경경영체계를 구축하고 환경경영 목표를 수립하여 온실가스 배출량과 에너지소비 등에 대한 관리를 강화하고 중장기 전략을 수립하여 단계적으로 2050 탄소중립을 \n",
      "현대홈쇼핑은 내부 환경경영체계를 구축하고 환경경영 목표를 수립하여 온실가스 배출량과 에너지소비 등에 대한 관리를 강화하고 중장기 전략을 수립하여 단계적으로 2050 탄소중립을\n",
      "tensor([[    0,  1369,  4186,   311,   222,  4328,   222, 13784,   222,  2255,\n",
      "           222,  2459,   321,   222,    41,    38,    49,   222,  5297,   291,\n",
      "           222,   863,   222,  2291,  3738,   482,   222,  1477,   515,   222,\n",
      "          1001,  2414,   222,   935,   364,   222,   519,   411,   222,  1409,\n",
      "          2031,   222,  7103,   222,  2734,   291,   222,  1494,  1716,   222,\n",
      "           968,  1409,  1382,   972,   222,  7189, 34939,   222,  1409,  2255,\n",
      "          3210,   222,  1161,   291]])\n",
      "현대홈쇼핑은 친환경 중장기 경영 전략인 HEP 실현을 위해 2021년 10월 관리담당 사업부 직할 환경분야 전담 조직을 구성했고 안전환경파트에서는 전사적인 환경경영체계 운영을\n",
      "현대홈쇼핑은 친환경 중장기 경영 전략인 HEP 실현을 위해 2021년 10월 관리담당 사업부 직할 환경분야 전담 조직을 구성했고 안전환경파트에서는 전사적인 환경경영체계 운영을\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11064\\3197899210.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdecoded_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\82105\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\82105\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\transformers\\generation\\utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[0;32m   1520\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1521\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1522\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1523\u001b[0m             )\n\u001b[0;32m   1524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\82105\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\transformers\\generation\\utils.py\u001b[0m in \u001b[0;36mbeam_sample\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3123\u001b[0m             )\n\u001b[0;32m   3124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"past_key_values\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3125\u001b[1;33m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"past_key_values\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reorder_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"past_key_values\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3127\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict_in_generate\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0moutput_scores\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\82105\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36m_reorder_cache\u001b[1;34m(self, past, beam_idx)\u001b[0m\n\u001b[0;32m   1759\u001b[0m                 \u001b[1;31m# need to set correct `past` for each of the four key / value states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1760\u001b[0m                 reordered_layer_past_states = reordered_layer_past_states + (\n\u001b[1;32m-> 1761\u001b[1;33m                     \u001b[0mlayer_past_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_past_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1762\u001b[0m                 )\n\u001b[0;32m   1763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for _, item in acc.iterrows():\n",
    "#     inputs = item['text']\n",
    "#     inputs = tokenizer(inputs, max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "#     output = model.generate(**inputs, num_beams=3, do_sample=True, min_length=10, max_length=128)\n",
    "#     print(output)\n",
    "#     decoded_output = tokenizer.batch_decode(output, skip_special_tokens=False)[0]\n",
    "#     print(decoded_output)\n",
    "#     result = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "#     print(result)\n",
    "#     out.loc[out['keyword']==item['keyword'], 'text'] = result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec8dee48dbbcaba4ab33c211cc3985cb6ada4ac8ebaeb72c3fb14197585c2120"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
